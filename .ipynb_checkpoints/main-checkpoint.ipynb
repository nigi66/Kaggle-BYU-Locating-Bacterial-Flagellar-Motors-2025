{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4ca3a75-e7b2-44e9-abf9-110512894ef4",
   "metadata": {},
   "source": [
    "# prepare data for yolo11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fd96d6-b31b-4d53-b43b-59c22f53ed37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import yaml\n",
    "\n",
    "\n",
    "# Define YOLO dataset structure and parameters\n",
    "data_path = \"/kaggle/input/byu-locating-bacterial-flagellar-motors-2025/\"\n",
    "train_dir = os.path.join(data_path, \"train\")\n",
    "\n",
    "# Output directories for YOLO dataset (adjust as needed)\n",
    "yolo_dataset_dir = \"/kaggle/working/yolo_dataset\"\n",
    "yolo_images_train = os.path.join(yolo_dataset_dir, \"images\", \"train\")\n",
    "yolo_images_val = os.path.join(yolo_dataset_dir, \"images\", \"val\")\n",
    "yolo_labels_train = os.path.join(yolo_dataset_dir, \"labels\", \"train\")\n",
    "yolo_labels_val = os.path.join(yolo_dataset_dir, \"labels\", \"val\")\n",
    "\n",
    "# Create necessary directories\n",
    "for dir_path in [yolo_images_train, yolo_images_val, yolo_labels_train, yolo_labels_val]:\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "# Define constants for processing\n",
    "TRUST = 2      # Number of slices above and below center slice (total slices = 2*TRUST + 1)\n",
    "BOX_SIZE = 32   # Bounding box size (in pixels)\n",
    "TRAIN_SPLIT = 0.8  # 80% training, 20% validation\n",
    "\n",
    "# Define a helper function for image normalization using percentile-based contrast enhancement.\n",
    "def normalize_slice(slice_data):\n",
    "    \"\"\"\n",
    "    Normalize slice data using the 2nd and 98th percentiles.\n",
    "    \n",
    "    Args:\n",
    "        slice_data (numpy.array): Input image slice.\n",
    "    \n",
    "    Returns:\n",
    "        np.uint8: Normalized image in the range [0, 255].\n",
    "    \"\"\"\n",
    "    p2 = np.percentile(slice_data, 2)\n",
    "    p98 = np.percentile(slice_data, 98)\n",
    "    clipped_data = np.clip(slice_data, p2, p98)\n",
    "    normalized = 255 * (clipped_data - p2) / (p98 - p2)\n",
    "    return np.uint8(normalized)\n",
    "\n",
    "# Define the preprocessing function to extract slices, normalize, and generate YOLO annotations.\n",
    "def prepare_yolo_dataset(trust=TRUST, train_split=TRAIN_SPLIT):\n",
    "    \"\"\"\n",
    "    Extract slices containing motors and save images with corresponding YOLO annotations.\n",
    "    \n",
    "    Steps:\n",
    "    - Load the motor labels.\n",
    "    - Perform a train/validation split by tomogram.\n",
    "    - For each motor, extract slices in a range (Â± trust parameter).\n",
    "    - Normalize each slice and save it.\n",
    "    - Generate YOLO format bounding box annotations with a fixed box size.\n",
    "    - Create a YAML configuration file for YOLO training.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A summary containing dataset statistics and file paths.\n",
    "    \"\"\"\n",
    "    # Load the labels CSV\n",
    "    labels_df = pd.read_csv(os.path.join(data_path, \"train_labels.csv\"))\n",
    "    \n",
    "    total_motors = labels_df['Number of motors'].sum()\n",
    "    print(f\"Total number of motors in the dataset: {total_motors}\")\n",
    "    \n",
    "    # Consider only tomograms with at least one motor\n",
    "    tomo_df = labels_df[labels_df['Number of motors'] > 0].copy()\n",
    "    unique_tomos = tomo_df['tomo_id'].unique()\n",
    "    print(f\"Found {len(unique_tomos)} unique tomograms with motors\")\n",
    "    \n",
    "    # Shuffle and split tomograms into train and validation sets\n",
    "    np.random.shuffle(unique_tomos)\n",
    "    split_idx = int(len(unique_tomos) * train_split)\n",
    "    train_tomos = unique_tomos[:split_idx]\n",
    "    val_tomos = unique_tomos[split_idx:]\n",
    "    print(f\"Split: {len(train_tomos)} tomograms for training, {len(val_tomos)} tomograms for validation\")\n",
    "    \n",
    "    # Helper function to process a list of tomograms\n",
    "    def process_tomogram_set(tomogram_ids, images_dir, labels_dir, set_name):\n",
    "        motor_counts = []\n",
    "        for tomo_id in tomogram_ids:\n",
    "            # Get motor annotations for the current tomogram\n",
    "            tomo_motors = labels_df[labels_df['tomo_id'] == tomo_id]\n",
    "            for _, motor in tomo_motors.iterrows():\n",
    "                if pd.isna(motor['Motor axis 0']):\n",
    "                    continue\n",
    "                motor_counts.append(\n",
    "                    (tomo_id, \n",
    "                     int(motor['Motor axis 0']), \n",
    "                     int(motor['Motor axis 1']), \n",
    "                     int(motor['Motor axis 2']),\n",
    "                     int(motor['Array shape (axis 0)']))\n",
    "                )\n",
    "        \n",
    "        print(f\"Will process approximately {len(motor_counts) * (2 * trust + 1)} slices for {set_name}\")\n",
    "        processed_slices = 0\n",
    "        \n",
    "        # Loop over each motor annotation\n",
    "        for tomo_id, z_center, y_center, x_center, z_max in tqdm(motor_counts, desc=f\"Processing {set_name} motors\"):\n",
    "            z_min = max(0, z_center - trust)\n",
    "            z_max_bound = min(z_max - 1, z_center + trust)\n",
    "            for z in range(z_min, z_max_bound + 1):\n",
    "                # Create the slice filename and source path\n",
    "                slice_filename = f\"slice_{z:04d}.jpg\"\n",
    "                src_path = os.path.join(train_dir, tomo_id, slice_filename)\n",
    "                if not os.path.exists(src_path):\n",
    "                    print(f\"Warning: {src_path} does not exist, skipping.\")\n",
    "                    continue\n",
    "                \n",
    "                # Load, normalize, and save the image slice\n",
    "                img = Image.open(src_path)\n",
    "                img_array = np.array(img)\n",
    "                normalized_img = normalize_slice(img_array)\n",
    "                dest_filename = f\"{tomo_id}_z{z:04d}_y{y_center:04d}_x{x_center:04d}.jpg\"\n",
    "                dest_path = os.path.join(images_dir, dest_filename)\n",
    "                Image.fromarray(normalized_img).save(dest_path)\n",
    "                \n",
    "                # Prepare YOLO bounding box annotation (normalized values)\n",
    "                img_width, img_height = img.size\n",
    "                x_center_norm = x_center / img_width\n",
    "                y_center_norm = y_center / img_height\n",
    "                box_width_norm = BOX_SIZE / img_width\n",
    "                box_height_norm = BOX_SIZE / img_height\n",
    "                label_path = os.path.join(labels_dir, dest_filename.replace('.jpg', '.txt'))\n",
    "                with open(label_path, 'w') as f:\n",
    "                    f.write(f\"0 {x_center_norm} {y_center_norm} {box_width_norm} {box_height_norm}\\n\")\n",
    "                \n",
    "                processed_slices += 1\n",
    "        \n",
    "        return processed_slices, len(motor_counts)\n",
    "    \n",
    "    # Process training tomograms\n",
    "    train_slices, train_motors = process_tomogram_set(train_tomos, yolo_images_train, yolo_labels_train, \"training\")\n",
    "    # Process validation tomograms\n",
    "    val_slices, val_motors = process_tomogram_set(val_tomos, yolo_images_val, yolo_labels_val, \"validation\")\n",
    "    \n",
    "    # Generate YAML configuration for YOLO training\n",
    "    yaml_content = {\n",
    "        'path': yolo_dataset_dir,\n",
    "        'train': 'images/train',\n",
    "        'val': 'images/val',\n",
    "        'names': {0: 'motor'}\n",
    "    }\n",
    "    with open(os.path.join(yolo_dataset_dir, 'dataset.yaml'), 'w') as f:\n",
    "        yaml.dump(yaml_content, f, default_flow_style=False)\n",
    "    \n",
    "    print(f\"\\nProcessing Summary:\")\n",
    "    print(f\"- Train set: {len(train_tomos)} tomograms, {train_motors} motors, {train_slices} slices\")\n",
    "    print(f\"- Validation set: {len(val_tomos)} tomograms, {val_motors} motors, {val_slices} slices\")\n",
    "    print(f\"- Total: {len(train_tomos) + len(val_tomos)} tomograms, {train_motors + val_motors} motors, {train_slices + val_slices} slices\")\n",
    "    \n",
    "    return {\n",
    "        \"dataset_dir\": yolo_dataset_dir,\n",
    "        \"yaml_path\": os.path.join(yolo_dataset_dir, 'dataset.yaml'),\n",
    "        \"train_tomograms\": len(train_tomos),\n",
    "        \"val_tomograms\": len(val_tomos),\n",
    "        \"train_motors\": train_motors,\n",
    "        \"val_motors\": val_motors,\n",
    "        \"train_slices\": train_slices,\n",
    "        \"val_slices\": val_slices\n",
    "    }\n",
    "\n",
    "# Run the preprocessing\n",
    "summary = prepare_yolo_dataset(TRUST)\n",
    "print(f\"\\nPreprocessing Complete:\")\n",
    "print(f\"- Training data: {summary['train_tomograms']} tomograms, {summary['train_motors']} motors, {summary['train_slices']} slices\")\n",
    "print(f\"- Validation data: {summary['val_tomograms']} tomograms, {summary['val_motors']} motors, {summary['val_slices']} slices\")\n",
    "print(f\"- Dataset directory: {summary['dataset_dir']}\")\n",
    "print(f\"- YAML configuration: {summary['yaml_path']}\")\n",
    "print(\"\\nReady for YOLO training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dcdd39-0451-4e44-b6e0-4cff17fa5b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install /kaggle/input/ultralytics/ultralytics-8.3.127-py3-none-any.whl --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89388820-8f3d-4dfa-a14e-55588628b7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pre-trained YOLOv10n model\n",
    "model = YOLO('/kaggle/input/yolo11/pytorch/default/1/yolo11l.pt')  # yolov8n/8s/8m/8l also work, or custom yolov10 weights\n",
    "\n",
    "# Train the model on your custom dataset\n",
    "model.train(\n",
    "    data=summary['yaml_path'],   # dataset.yaml path\n",
    "    epochs=30,\n",
    "    imgsz=1024,\n",
    "    batch=8,\n",
    "    lr0=0.0005, \n",
    "    name='motor',\n",
    "    freeze=10\n",
    "    #device='cpu'  # use \"device='cpu'\" for CPU only\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64077bb-3108-4130-8ef9-c52124366775",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee2231f3-1a60-40fc-8fc1-ebe9000c0e39",
   "metadata": {},
   "source": [
    "# combine yolo prediction with cnn model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e18306b-854d-4829-8777-d519ec9ed67c",
   "metadata": {},
   "source": [
    "# prepare and save data for cnn classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424ff44e-ca50-4ca0-912a-b77a1052f2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define directories\n",
    "TRAIN_IMAGE_ROOT = '/kaggle/input/byu-locating-bacterial-flagellar-motors-2025/train'\n",
    "OUTPUT_DIR = 'motor_patches'  # Stores class_1 (motor) and class_0 (non-motor)\n",
    "\n",
    "# Ensure output directories exist\n",
    "os.makedirs(os.path.join(OUTPUT_DIR, 'class_1'), exist_ok=True)  # Class 1 = Motor\n",
    "os.makedirs(os.path.join(OUTPUT_DIR, 'class_0'), exist_ok=True)  # Class 0 = Non-motor\n",
    "\n",
    "# Load the training labels\n",
    "labels_df = pd.read_csv('/kaggle/input/byu-locating-bacterial-flagellar-motors-2025/train_labels.csv')\n",
    "\n",
    "# Parameters\n",
    "CROP_SIZE = 64\n",
    "TRUST = 4\n",
    "NEG_PATCHES_PER_TOMO = 20  # How many negative patches to extract per tomogram\n",
    "\n",
    "def extract_patches():\n",
    "    ### 1. Extract motor patches (class 1)\n",
    "    print(\"ð Extracting motor (class 1) patches...\")\n",
    "    motor_df = labels_df[labels_df['Number of motors'] > 0].copy()\n",
    "    \n",
    "    for _, row in tqdm(motor_df.iterrows(), total=len(motor_df)):\n",
    "        tomo_id = row['tomo_id']\n",
    "        motor_x = row['Motor axis 2']\n",
    "        motor_y = row['Motor axis 1']\n",
    "        motor_z = row['Motor axis 0']\n",
    "        \n",
    "        if any(pd.isna([motor_x, motor_y, motor_z])):\n",
    "            continue\n",
    "\n",
    "        for z in range(int(motor_z - TRUST), int(motor_z + TRUST + 1)):\n",
    "            slice_file = f\"slice_{z:04d}.jpg\"\n",
    "            slice_path = os.path.join(TRAIN_IMAGE_ROOT, tomo_id, slice_file)\n",
    "\n",
    "            if not os.path.exists(slice_path):\n",
    "                continue\n",
    "\n",
    "            img = Image.open(slice_path).convert('RGB')\n",
    "            W, H = img.size\n",
    "\n",
    "            # Clamp crop box\n",
    "            left = int(max(0, motor_x - CROP_SIZE / 2))\n",
    "            top = int(max(0, motor_y - CROP_SIZE / 2))\n",
    "            right = min(W, left + CROP_SIZE)\n",
    "            bottom = min(H, top + CROP_SIZE)\n",
    "\n",
    "            patch = img.crop((left, top, right, bottom)).resize((CROP_SIZE, CROP_SIZE))\n",
    "            save_path = os.path.join(OUTPUT_DIR, 'class_1', f\"{tomo_id}_z{z:04d}_motor.jpg\")\n",
    "            patch.save(save_path)\n",
    "\n",
    "    ### 2. Extract non-motor patches (class 0)\n",
    "    print(\"ð Extracting non-motor (class 0) patches...\")\n",
    "    no_motor_df = labels_df[labels_df['Number of motors'] == 0].copy()\n",
    "    used_coords = set()  # Optional: avoid duplicate regions\n",
    "\n",
    "    for _, row in tqdm(no_motor_df.iterrows(), total=len(no_motor_df)):\n",
    "        tomo_id = row['tomo_id']\n",
    "        tomo_dir = os.path.join(TRAIN_IMAGE_ROOT, tomo_id)\n",
    "        slice_files = sorted([f for f in os.listdir(tomo_dir) if f.endswith('.jpg')])\n",
    "        slice_indices = [int(f.split('_')[1].replace('.jpg', '')) for f in slice_files]\n",
    "\n",
    "        random_slices = random.sample(slice_indices, min(NEG_PATCHES_PER_TOMO, len(slice_indices)))\n",
    "\n",
    "        for z in random_slices:\n",
    "            slice_file = f\"slice_{z:04d}.jpg\"\n",
    "            slice_path = os.path.join(tomo_dir, slice_file)\n",
    "            if not os.path.exists(slice_path):\n",
    "                continue\n",
    "\n",
    "            img = Image.open(slice_path).convert('RGB')\n",
    "            W, H = img.size\n",
    "\n",
    "            for _ in range(2):  # 2 random patches per slice\n",
    "                x = random.randint(0, W - CROP_SIZE)\n",
    "                y = random.randint(0, H - CROP_SIZE)\n",
    "                patch = img.crop((x, y, x + CROP_SIZE, y + CROP_SIZE)).resize((CROP_SIZE, CROP_SIZE))\n",
    "                save_path = os.path.join(OUTPUT_DIR, 'class_0', f\"{tomo_id}_z{z:04d}_x{x}_y{y}_nonmotor.jpg\")\n",
    "                patch.save(save_path)\n",
    "\n",
    "extract_patches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc96214-9cb4-45e5-8379-ba34e97ff102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "362c7f0c-8675-48b6-92b2-43b323524ded",
   "metadata": {},
   "source": [
    "# train cnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7be91a8-9e46-486f-a200-92cb7afab19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Define paths\n",
    "train_dir = 'motor_patches'\n",
    "batch_size = 32\n",
    "img_size = (64, 64)  # Use the same size as the crop size\n",
    "\n",
    "# Setup data generators (assuming directory structure: 'class_0' and 'class_1' for negative/positive samples)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# CNN Model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=17,\n",
    "    validation_data=validation_generator\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "model.save('motor_classifier.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9ffd73-bcc4-4149-aa47-7c9206d915b7",
   "metadata": {},
   "source": [
    "# prepare submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0469687b-4f5d-432d-8247-c32e65562c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from ultralytics import YOLO\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from PIL import Image\n",
    "\n",
    "# === Paths ===\n",
    "CNN_MODEL_PATH = \"/kaggle/input/cnn-classifier/motor_classifier.h5\"\n",
    "YOLO_MODEL_PATH = \"/kaggle/input/best-pt/best.pt\"\n",
    "TEST_DIR = \"/kaggle/input/byu-locating-bacterial-flagellar-motors-2025/test\"\n",
    "OUT_CSV = \"/kaggle/working/submission.csv\"\n",
    "\n",
    "# === Parameters ===\n",
    "CONF_THRESHOLD = 0.7\n",
    "CROP_SIZE = 64\n",
    "CNN_THRESHOLD = 0.7  # CNN softmax score threshold for motor class\n",
    "TOP_N = 1\n",
    "# === Load Models ===\n",
    "print(\"Loading models...\")\n",
    "yolo_model = YOLO(YOLO_MODEL_PATH)\n",
    "cnn_model = load_model(CNN_MODEL_PATH)\n",
    "\n",
    "# === Gather test images ===\n",
    "test_image_paths = sorted(glob(os.path.join(TEST_DIR, 'tomo_*', 'slice_*.jpg')))\n",
    "tomo_slices = defaultdict(list)\n",
    "for img_path in test_image_paths:\n",
    "    tomo_id = os.path.basename(os.path.dirname(img_path))\n",
    "    tomo_slices[tomo_id].append(img_path)\n",
    "\n",
    "results_data = []\n",
    "\n",
    "# === Helper: Crop and classify using CNN ===\n",
    "def classify_crop(image_path, x, y, w, h, crop_size=CROP_SIZE):\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    img_width, img_height = img.size\n",
    "\n",
    "    # Convert center-x, center-y to box\n",
    "    left = int(x - crop_size / 2)\n",
    "    top = int(y - crop_size / 2)\n",
    "    right = int(x + crop_size / 2)\n",
    "    bottom = int(y + crop_size / 2)\n",
    "\n",
    "    # Clamp box\n",
    "    left = max(0, left)\n",
    "    top = max(0, top)\n",
    "    right = min(img_width, right)\n",
    "    bottom = min(img_height, bottom)\n",
    "\n",
    "    crop = img.crop((left, top, right, bottom)).resize((crop_size, crop_size))\n",
    "    arr = img_to_array(crop) / 255.0\n",
    "    arr = np.expand_dims(arr, axis=0)\n",
    "\n",
    "    preds = cnn_model.predict(arr, verbose=0)[0]\n",
    "    return preds[0]  # Class 1 = motor score\n",
    "\n",
    "# === Process each tomogram ===\n",
    "for tomo_id, image_paths in tqdm(tomo_slices.items(), desc=\"Processing tomograms\"):\n",
    "    detections = []\n",
    "\n",
    "    for img_path in sorted(image_paths):\n",
    "        slice_file = os.path.basename(img_path)\n",
    "        slice_number = int(slice_file.replace(\"slice_\", \"\").replace(\".jpg\", \"\"))\n",
    "\n",
    "        # Run YOLO\n",
    "        results = yolo_model(img_path, verbose=False)[0]\n",
    "        boxes = results.boxes.data.cpu().numpy()\n",
    "\n",
    "        for box in boxes:\n",
    "            x_center, y_center, width, height, conf, cls = box\n",
    "            if conf < CONF_THRESHOLD:\n",
    "                continue\n",
    "\n",
    "            # Run CNN classification\n",
    "            cnn_score = classify_crop(img_path, x_center, y_center, width, height)\n",
    "            if cnn_score >= CNN_THRESHOLD:\n",
    "                detections.append({\n",
    "                    'tomo_id': tomo_id,\n",
    "                    'Motor axis 0': round(float(slice_number), 1),\n",
    "                    'Motor axis 1': round(float(y_center), 1),\n",
    "                    'Motor axis 2': round(float(x_center), 1),\n",
    "                    'confidence' : round(float(conf), 4)\n",
    "                })\n",
    "\n",
    "    # Keep only top-N highest confidence detections (optional)\n",
    "    if detections:\n",
    "        detections.sort(key=lambda x: x['confidence'], reverse=True)\n",
    "        if TOP_N is not None:\n",
    "            detections = detections[:TOP_N]\n",
    "        results_data.extend(detections)\n",
    "    else:\n",
    "        # No detections: write default -1\n",
    "        results_data.append({\n",
    "            'tomo_id': tomo_id,\n",
    "            'Motor axis 0': -1,\n",
    "            'Motor axis 1': -1,\n",
    "            'Motor axis 2': -1,\n",
    "        })\n",
    "\n",
    "df_results = pd.DataFrame(results_data)\n",
    "\n",
    "# Remove the confidence column if it exists\n",
    "if 'confidence' in df_results.columns:\n",
    "    df_results = df_results.drop(columns=['confidence'])\n",
    "\n",
    "# === Save ===\n",
    "#df = pd.DataFrame(results_data)\n",
    "df_results.to_csv(OUT_CSV, index=False)\n",
    "print(f\"Saved filtered predictions to: {OUT_CSV}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3027574-8ced-4555-9f80-863f5a6dd7d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ad3964-8e58-46ff-a301-b436a5f3a3d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c2fe0f-00dc-430d-964c-c293a9ac4e61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
